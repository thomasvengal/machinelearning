{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression for Multiclass classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Logistic model</b>  is used to model the probability of a certain class or event existing such as pass/fail, win/lose, alive/dead or healthy/sick.\n",
    "\n",
    "A <b>binary logistic model</b> has a dependent variable with two possible values, such as pass/fail which is represented by labels 1/0. \n",
    "\n",
    "<div align=\"right\">   Reference: Wikipedia </div> \n",
    "\n",
    "In this session, we will perform multinomial classification by using logistic regression model. It is also known as Softmax Classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import and preprocess the dataset\n",
    "\n",
    "Iris dataset consists of 150 observations.\n",
    "\n",
    "The features or attributed (columns) are Sepal Length, Sepal Width, Petal Length and Petal Width.\n",
    "\n",
    "The observations (rows) belong to 3 different types of iris species - Setosa, Versicolour, and Virginica. Each class has 50 observations.\n",
    "\n",
    "The iris dataset can be downloded from Kaggle: https://www.kaggle.com/uciml/iris as csv file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Iris dataset.\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "# Extract two columns from the dataset for X values.\n",
    "# X is  petal length, petal width.\n",
    "# y is the target column.\n",
    "\n",
    "X = iris[\"data\"][:,(2,3)]  \n",
    "y = iris[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test\n",
    "\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(X, y, stratify=y, test_size= 0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create and train the machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the model\n",
    "\n",
    "model_softmax = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", C=5) \n",
    "# default values are used\n",
    "\n",
    "model_softmax.fit(X_train,y_train) # train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the values\n",
    "\n",
    "y_prob  = model_softmax.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Performance measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.77777777777777\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, y_prob)\n",
    "print(acc * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[15  0  0]\n",
      " [ 0 14  1]\n",
      " [ 0  0 15]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_prob) \n",
    "print('Confusion Matrix :')\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      0.93      0.97        15\n",
      "           2       0.94      1.00      0.97        15\n",
      "\n",
      "   micro avg       0.98      0.98      0.98        45\n",
      "   macro avg       0.98      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_prob))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
